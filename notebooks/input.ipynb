{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import utils\n",
    "utils.mount_src()\n",
    "\n",
    "DATA_PATH = \"E:/30-39 Estudos/36 Mestrado/36.03 Deep learning para computação visual/Projeto/flickr_scraper/images\"\n",
    "METADATA = DATA_PATH + \"/metadata.csv\"\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pathlib\n",
    "import polars as pl\n",
    "import filetype\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    data_path: pathlib.Path\n",
    "    df: pl.DataFrame\n",
    "\n",
    "\n",
    "    def __init__(self, data_path: str):\n",
    "        self.data_path = pathlib.Path(data_path)\n",
    "        self.df = pl.read_csv(self.data_path / \"metadata.csv\")\n",
    "    \n",
    "\n",
    "    def dataset(self, target_size=(224, 224), batch_size=32) -> tf.data.Dataset:\n",
    "        # Clean-up dataset\n",
    "        self.df = self.__filter_out_gifs(self.df)\n",
    "        self.df = self.__filter_out_non_existent_files(self.df)\n",
    "\n",
    "        paths: pl.Series = str(self.data_path) + \"/\" + self.df[\"year\"].cast(pl.String) \n",
    "        paths += \"/\" + self.df[\"id\"].cast(pl.String) + \".jpg\"\n",
    "        paths = paths.to_numpy()\n",
    "        years = self.df[\"year\"].to_numpy()\n",
    "        lats = self.df[\"latitude\"].to_numpy()\n",
    "        lons = self.df[\"longitude\"].to_numpy()\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((paths, years, lats, lons))\n",
    "        dataset = dataset.map(\n",
    "            lambda path, year, lat, lon: DataLoader.load_image_and_labels(path, year, lat, lon, image_shape=target_size)\n",
    "        )\n",
    "\n",
    "        dataset = dataset.shuffle(buffer_size=len(paths)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_image_and_labels(path: str, year: int, lat: float, lon: float, image_shape=(224, 224)):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, image_shape) / 255.0\n",
    "        return img, {\n",
    "            \"year\": year,\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon\n",
    "        }\n",
    "\n",
    "\n",
    "    def __filter_out_gifs(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        def is_gif(filepath: str) -> bool:\n",
    "            guess = filetype.guess(filepath)\n",
    "            return guess.mime == \"image/gif\"\n",
    "        \n",
    "        original_columns = df.columns\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                str(self.data_path) + \"/\" + pl.col(\"year\").cast(pl.String) + \"/\" + pl.col(\"id\").cast(pl.String) + \".jpg\"\n",
    "            ).alias(\"filepath\")\n",
    "        )\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                df[\"filepath\"].map_elements(is_gif, return_dtype=pl.Boolean)\n",
    "            ).alias(\"is_gif\")\n",
    "        )\n",
    "        df = df.filter(~pl.col(\"is_gif\"))\n",
    "        return df.select(original_columns)\n",
    "    \n",
    "\n",
    "    def __filter_out_non_existent_files(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        def file_exists(filepath: str) -> bool:\n",
    "            file = pathlib.Path(filepath)\n",
    "            return file.is_file()\n",
    "        \n",
    "        original_columns = df.columns\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                str(self.data_path) + \"/\" + pl.col(\"year\").cast(pl.String) + \"/\" + pl.col(\"id\").cast(pl.String) + \".jpg\"\n",
    "            ).alias(\"filepath\")\n",
    "        )\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                df[\"filepath\"].map_elements(file_exists, return_dtype=pl.Boolean)\n",
    "            ).alias(\"file_exists\")\n",
    "        )\n",
    "        df = df.filter(pl.col(\"file_exists\"))\n",
    "        return df.select(original_columns)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data_loader = DataLoader(DATA_PATH)\n",
    "print(\"Original df length: \" + str(len(data_loader.df)))\n",
    "df = data_loader.cleanup_df()\n",
    "data_loader.df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "paths = DATA_PATH + \"/\" + data_loader.df[\"year\"].cast(pl.String) + \"/\" + data_loader.df[\"id\"].cast(pl.String) + \".jpg\"\n",
    "paths = paths.to_numpy()\n",
    "years = data_loader.df[\"year\"].to_numpy()\n",
    "lats = data_loader.df[\"latitude\"].to_numpy()\n",
    "lons = data_loader.df[\"longitude\"].to_numpy()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def load_image_and_label(path: str, year: int, lat: float, lon: float, image_shape=(224, 224)):\n",
    "    try:\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, image_shape) / 255.0\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "        tf.print(f\"Error on path {path}\")\n",
    "        raise e\n",
    "    return img, {\n",
    "        \"year\": year,\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "#tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((paths, years, lats, lons))\n",
    "dataset = dataset.map(lambda path, year, lat, lon: load_image_and_label(path, year, lat, lon))\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(buffer_size=len(paths)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_img = tf.keras.Input(shape=(224, 224, 3), name=\"image\")\n",
    "    x = tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\")(input_img)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "    output_year = tf.keras.layers.Dense(1, name=\"year\")(x)\n",
    "    output_lat = tf.keras.layers.Dense(1, name=\"lat\")(x)\n",
    "    output_lon = tf.keras.layers.Dense(1, name=\"lon\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=input_img, outputs={\"year\": output_year, \"lat\": output_lat, \"lon\": output_lon})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "#model.build(input_shape=(None, 224, 224, 3))\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"year\": \"mse\", \"lat\": \"mse\", \"lon\": \"mse\"},\n",
    "    metrics={\"year\": \"mae\", \"lat\": \"mae\", \"lon\": \"mae\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "data_loader = DataLoader(DATA_PATH)\n",
    "dataset = data_loader.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [i for i in range(1, 6)]\n",
    "\n",
    "plt.plot(epochs, history.history[\"lon_mae\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "\n",
    "example = DATA_PATH + \"/1929/\" + \"2123423918.jpg\"\n",
    "img = load_img(example)\n",
    "img\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "metadata_for_year = pl.read_csv(DATA_PATH + \"/1929/metadata.csv\")\n",
    "labels = metadata_for_year.filter(pl.col(\"id\") == 2123423918)\n",
    "labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def load_and_preprocess_image(path, image_shape=(224, 224)):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, image_shape) / 255.0\n",
    "    return img\n",
    "\n",
    "img = load_and_preprocess_image(example)\n",
    "img_batch = tf.expand_dims(img, axis=0)\n",
    "model.predict(img_batch)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
